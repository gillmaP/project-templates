# Hydra + DDP Template

A template with powerful configuration management using Hydra and manual PyTorch DDP management.

## ğŸ“‹ Structure

```
project/
â”œâ”€â”€ main.py                 # Uses Hydra decorator
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml        # Main configuration
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ cnn.yaml       # Model-specific configs
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset.yaml   # Dataset configuration
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ default.yaml   # Training configuration
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ datasets.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.py
â””â”€â”€ utils/
    â””â”€â”€ train_util.py
```

## ğŸ¯ Features

- **Hierarchical Configuration**: Modular configuration separation
- **Automatic Experiment Saving**: All experiment configs automatically saved
- **Hyperparameter Sweeps**: Automatic sweeps with multi-run
- **Type Safety**: Type checking with OmegaConf

## ğŸš€ Usage

### Basic Execution
```bash
python main.py
```

### Configuration Override
```bash
python main.py train.learning_rate=1e-5 model.embed_dim=512
```

### Hyperparameter Sweep
```bash
python main.py -m train.learning_rate=1e-4,1e-5,1e-6
```

### Multi GPU
```bash
torchrun --nproc_per_node=4 main.py
```

## ğŸ“ Key Code Patterns

### Hydra Main Function
```python
import hydra
from omegaconf import DictConfig

@hydra.main(config_path="configs", config_name="config", version_base=None)
def main(cfg: DictConfig):
    # cfg is a DictConfig object
    lr = cfg.train.learning_rate
    model = YourModel(**cfg.model)
```

### DDP Initialization
```python
import torch.distributed as dist

def setup_ddp(rank, world_size):
    dist.init_process_group(
        backend='nccl',
        init_method='env://',
        world_size=world_size,
        rank=rank
    )
    torch.cuda.set_device(rank)
```

### Experiment Output Directory
```python
# Hydra automatically creates outputs/date_time/ folder
output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
```

## âš™ï¸ Configuration File Structure

### configs/config.yaml
```yaml
defaults:
  - model: cnn
  - data: dataset
  - train: default

experiment:
  name: my_experiment
  seed: 42
```

### configs/train/default.yaml
```yaml
batch_size: 64
learning_rate: 1.0e-4
steps: 2000
```

## âœ… Pros

- Powerful configuration management (hierarchical, modular)
- Automatic experiment tracking (all configs saved)
- Easy hyperparameter sweeps
- Type safety

## âŒ Cons

- Steep learning curve (need to learn Hydra)
- Manual DDP management required
- Increased code complexity
- Difficult debugging
