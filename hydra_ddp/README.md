# Hydra + DDP í…œí”Œë¦¿

Hydraë¥¼ ì‚¬ìš©í•œ ê°•ë ¥í•œ ì„¤ì • ê´€ë¦¬ì™€ PyTorch DDPë¥¼ ì§ì ‘ ê´€ë¦¬í•˜ëŠ” í…œí”Œë¦¿ì…ë‹ˆë‹¤.

## ğŸ“‹ êµ¬ì¡°

```
project/
â”œâ”€â”€ main.py                 # Hydra ë°ì½”ë ˆì´í„° ì‚¬ìš©
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml        # ë©”ì¸ ì„¤ì •
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ cnn.yaml       # ëª¨ë¸ë³„ ì„¤ì •
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset.yaml    # ë°ì´í„°ì…‹ ì„¤ì •
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ default.yaml    # í•™ìŠµ ì„¤ì •
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ datasets.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.py
â””â”€â”€ utils/
    â””â”€â”€ train_util.py
```

## ğŸ¯ íŠ¹ì§•

- **ê³„ì¸µì  ì„¤ì •**: ëª¨ë“ˆë³„ ì„¤ì • ë¶„ë¦¬
- **ìë™ ì‹¤í—˜ ì €ì¥**: ëª¨ë“  ì‹¤í—˜ ì„¤ì • ìë™ ì €ì¥
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•**: Multi-runìœ¼ë¡œ ìë™ ìŠ¤ìœ•
- **íƒ€ì… ì•ˆì „ì„±**: OmegaConfë¡œ íƒ€ì… ì²´í¬

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰
```bash
python main.py
```

### ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
```bash
python main.py train.learning_rate=1e-5 model.embed_dim=512
```

### í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•
```bash
python main.py -m train.learning_rate=1e-4,1e-5,1e-6
```

### ë©€í‹° GPU
```bash
torchrun --nproc_per_node=4 main.py
```

## ğŸ“ ì£¼ìš” ì½”ë“œ íŒ¨í„´

### Hydra ë©”ì¸ í•¨ìˆ˜
```python
import hydra
from omegaconf import DictConfig

@hydra.main(config_path="configs", config_name="config", version_base=None)
def main(cfg: DictConfig):
    # cfgëŠ” DictConfig ê°ì²´
    lr = cfg.train.learning_rate
    model = YourModel(**cfg.model)
```

### DDP ì´ˆê¸°í™”
```python
import torch.distributed as dist

def setup_ddp(rank, world_size):
    dist.init_process_group(
        backend='nccl',
        init_method='env://',
        world_size=world_size,
        rank=rank
    )
    torch.cuda.set_device(rank)
```

### ì‹¤í—˜ ì €ì¥ ê²½ë¡œ
```python
# Hydraê°€ ìë™ìœ¼ë¡œ outputs/ë‚ ì§œ_ì‹œê°„/ í´ë” ìƒì„±
output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
```

## âš™ï¸ ì„¤ì • íŒŒì¼ êµ¬ì¡°

### configs/config.yaml
```yaml
defaults:
  - model: cnn
  - data: dataset
  - train: default

experiment:
  name: my_experiment
  seed: 42
```

### configs/train/default.yaml
```yaml
batch_size: 64
learning_rate: 1.0e-4
steps: 2000
```

## âœ… ì¥ì 

- ê°•ë ¥í•œ ì„¤ì • ê´€ë¦¬ (ê³„ì¸µì , ëª¨ë“ˆí™”)
- ìë™ ì‹¤í—˜ ì¶”ì  (ëª¨ë“  ì„¤ì • ì €ì¥)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ• ì‰¬ì›€
- íƒ€ì… ì•ˆì „ì„±

## âŒ ë‹¨ì 

- í•™ìŠµ ê³¡ì„  ë†’ìŒ (Hydra í•™ìŠµ í•„ìš”)
- DDP ì§ì ‘ ê´€ë¦¬ í•„ìš”
- ì½”ë“œ ë³µì¡ë„ ì¦ê°€
- ë””ë²„ê¹… ì–´ë ¤ì›€

